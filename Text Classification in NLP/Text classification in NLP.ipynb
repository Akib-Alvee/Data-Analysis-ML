{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1be4b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_curve,auc\n",
    "from textblob import Word\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0b022b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "train = fetch_20newsgroups(subset='train', shuffle=True)\n",
    "train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51c42022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cbfa7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(train.data[0].split(\"\\n\")[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "428536be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: guykuo@carson.u.washington.edu (Guy Kuo)\n",
      "Subject: SI Clock Poll - Final Call\n",
      "Summary: Final call for SI clock reports\n",
      "Keywords: SI,acceleration,clock,upgrade\n",
      "Article-I.D.: shelley.1qvfo9INNc3s\n",
      "Organization: University of Washington\n",
      "Lines: 11\n",
      "NNTP-Posting-Host: carson.u.washington.edu\n",
      "\n",
      "A fair number of brave souls who upgraded their SI clock oscillator have\n",
      "shared their experiences for this poll. Please send a brief message detailing\n",
      "your experiences with the procedure. Top speed attained, CPU rated speed,\n",
      "add on cards and adapters, heat sinks, hour of usage per day, floppy disk\n",
      "functionality with 800 and 1.4 m floppies are especially requested.\n",
      "\n",
      "I will be summarizing in the next two days, so please add to the network\n",
      "knowledge base if you have done the clock upgrade and haven't answered this\n",
      "poll. Thanks.\n",
      "\n",
      "Guy Kuo <guykuo@u.washington.edu>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(train.data[1].split(\"\\n\")[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a1f8a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.autos\n"
     ]
    }
   ],
   "source": [
    "print(train.target_names[train.target[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e905c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.sys.mac.hardware\n"
     ]
    }
   ],
   "source": [
    "print(train.target_names[train.target[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "378f2ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformations(dataframe):\n",
    "    \n",
    "    # make all character lower\n",
    "    dataframe['text'] = dataframe['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "    \n",
    "    # removing punctuations\n",
    "    dataframe['text'] = dataframe['text'].str.replace('[^\\w\\s]',' ')\n",
    "    \n",
    "    #numbers\n",
    "    dataframe['text'] = dataframe['text'].str.replace('\\d','')\n",
    "\n",
    "    # removing stopwords\n",
    "    sw = stopwords.words('english')\n",
    "    dataframe['text'] = dataframe['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n",
    "    \n",
    "    # rare characters deleting\n",
    "    sil = pd.Series(' '.join(dataframe['text']).split()).value_counts()[-1000:]\n",
    "    dataframe['text'] = dataframe['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in sil))\n",
    "    \n",
    "    # lemmatization\n",
    "    \n",
    "    dataframe['text'] = dataframe['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()])) \n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "357d5d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...       7\n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...       4\n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4\n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1\n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['text'] = pd.DataFrame(train.data)\n",
    "df['target'] = pd.Series(train.target)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3ffa506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14259/2607401895.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dataframe['text'] = dataframe['text'].str.replace('[^\\w\\s]',' ')\n",
      "/tmp/ipykernel_14259/2607401895.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dataframe['text'] = dataframe['text'].str.replace('\\d','')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lerxst wam umd edu thing subject car nntp post...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>guykuo carson u washington edu guy kuo subject...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twillis ec ecn purdue edu thomas e willis subj...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jgreen amber joe green subject weitek p organi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jcm head cfa harvard edu jonathan mcdowell sub...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  lerxst wam umd edu thing subject car nntp post...       7\n",
       "1  guykuo carson u washington edu guy kuo subject...       4\n",
       "2  twillis ec ecn purdue edu thomas e willis subj...       4\n",
       "3  jgreen amber joe green subject weitek p organi...       1\n",
       "4  jcm head cfa harvard edu jonathan mcdowell sub...      14"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = transformations(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f04673d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8fb1a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df['text'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a41c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = count_vect.fit_transform(train_df)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60513a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a7a2d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 91023)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = tfidf_transformer.fit_transform(train_df)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e395621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf,train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ef339bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9326498143892522"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train_tfidf,train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9bcfc609",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(train_df,train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ba8361a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9513876613045784"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(train_df,train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143ef0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
